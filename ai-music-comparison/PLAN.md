# AI Music Generation Comparison Tool - Implementation Plan

**Status**: Planning â†’ Implementation Ready
**Presentation**: AI Whisperers Buenos Aires (Tuesday evening)
**Timeline**: 4 full days (Saturday 1pm â†’ Tuesday evening)
**Approach**: Journey over guaranteed results â¤ï¸+ğŸŒ€=ğŸŒˆ

---

## Scoping Questions (Answered)

### 1. Existing Data âœ…
- **Baseline song**: `Whispers_del_Futuro.wav` (Suno.ai generated)
- **Metadata**: `Whispers_del_Futuro.json` (42 segments with audio features)
- **Lyrics**: `SONG.md` (complete lyrics + style tags)
- **Test segments**: `suno_test_segments.md` (3 segments formatted for Suno regeneration)

### 2. Local Models Selected âœ…
- **MusicGen** (Meta AudioCraft) - Instrumental comparison (300M-3.3B params)
- **Bark** (Suno AI) - Vocal comparison (MIT license, ~13 sec max)
- **Stable Audio Open Small** - Small model comparison (341M params, 11 sec)

### 3. MVP Scope âœ…
**3 test segments** (not full song):
- **Segment 7** (2.1s) - Instrumental break (bandoneÃ³n + trap beats)
- **Segment 10** (5s) - Chorus with layered vocals (emotional peak)
- **Segment 18** (5s) - Verse with conversational flow

**Comparison matrix**:
| Segment | Suno Baseline | MusicGen | Bark | Stable Audio |
|---------|---------------|----------|------|--------------|
| Seg 7 (Instrumental) | âœ… | âœ… | âŒ | âœ… |
| Seg 10 (Chorus/Vocal) | âœ… | âŒ | âœ… | âŒ |
| Seg 18 (Verse) | âœ… | âœ… | âœ… | âœ… |

### 4. Output Format âœ…
- **Audio files**: WAV format for each model/segment
- **librosa analysis**: Compare tempo, spectral features, MFCCs, chroma
- **Presentation**: Audio playback + visual comparison charts (optional)

### 5. Timeline âœ…
- **Presentation**: Tuesday evening
- **Available time**: 4 full human days (Saturday 1pm start)
- **Approach**: MVP focused on journey/learnings, not perfect recreation

### 6. Tech Stack âœ…
- **Python** for audio generation and analysis
- **Models**: MusicGen, Bark, Stable Audio Open
- **Analysis**: librosa, numpy, matplotlib (optional)
- **Environment**: M4 Max MacBook Pro (128GB RAM, 16 cores)

---

## Implementation Plan

### Phase 1: Baseline Generation (Suno.ai) âœ… COMPLETE
**Goal**: Create 3 baseline segments for comparison

**Tasks**:
1. âœ… Generate `suno_segment7_instrumental.wav` (Digital BandoneÃ³n) - 30MB
2. âœ… Generate `suno_segment10_chorus.wav` (Susurra Conmigo) - 8.6MB
3. âœ… Generate `suno_segment18_verse.wav` (Caos y Suerte) - 3.6MB

**Format**: Use exact style tags and lyrics from `suno_test_segments.md`

**Outputs**:
- âœ… 3 WAV files in `data/baseline/`
- âœ… Ready for comparison

---

### Phase 2: Local Model Setup âœ… COMPLETE (Partial)
**Goal**: Install and test local music generation models

**Reference**: `docs/external/AI_Music_Generation_Implementation_Guide.md` (comprehensive production guide)

**Strategy**: Separate venv per model to avoid dependency conflicts
- **Why**: MusicGen requires PyTorch 2.1.0 + ffmpeg 6.x, Bark/Stable Audio work with PyTorch 2.9.0 + ffmpeg 8.x
- **Result**: 3 of 4 venvs working, MusicGen deferred (Docker required)

**Virtual environments**:
```
âœ… venv-bark/         # PyTorch 2.9.0 + Bark (vocals)
âœ… venv-stable-audio/ # PyTorch 2.9.0 + Diffusers (instrumental)
âœ… venv-analysis/     # librosa (audio comparison)
âš ï¸  venv-musicgen/    # DEFERRED - Requires Docker (PyAV/ffmpeg incompatibility)
```

**Completed**:
1. âœ… **Bark venv** (`./scripts/setup_bark.sh`)
   - Python 3.11.14, PyTorch 2.9.0
   - 13-second generation limit (chunking required)
   - Requirements: `requirements-bark.txt`

2. âœ… **Stable Audio venv** (`./scripts/setup_stable_audio.sh`)
   - Python 3.11.14, PyTorch 2.9.0
   - Max 47 seconds, model: `stabilityai/stable-audio-open-1.0`
   - Requirements: `requirements-stable-audio.txt`

3. âœ… **Analysis venv** (`./scripts/setup_analysis.sh`)
   - Python 3.11.14, librosa + numpy + scipy
   - Requirements: `requirements-analysis.txt`

4. âš ï¸ **MusicGen venv** - BLOCKED
   - Issue: AudioCraft requires `av==11.0.0` (PyAV)
   - Problem: av 11.0.0 incompatible with system ffmpeg 8.x
   - Solution: Docker with ffmpeg 6.x (see `Dockerfile.musicgen`)
   - **Decision**: Defer to future work (MVP timeline priority)

**Outputs**:
- âœ… 3 working environments (Bark, Stable Audio, Analysis)
- âœ… Requirements files for reproducibility
- âœ… Docker setup prepared for future MusicGen work
- âš ï¸ MusicGen â†’ Future work (see Future Enhancements)

---

### Phase 3: Local Model Generation âœ… COMPLETE (Partial Success)
**Goal**: Generate comparison segments with local models (Bark + Stable Audio)

**Status**: Bark complete (âœ…), Stable Audio non-functional (âŒ)

**Tasks**:
1. âœ… **Bark generations** (vocals):
   - âœ… Segment 10: Chorus vocals (14.12s, "Susurra Conmigo")
   - âœ… Segment 18: Verse vocals (14.28s, "Caos y Suerte")
   - Fixed: PyTorch 2.6+ `weights_only` breaking change (monkey-patch torch.load)
   - Fixed: Cache permission issues (project-local .cache/)

2. âŒ **Stable Audio generations** (instrumental):
   - âŒ Segment 7: Instrumental break - NOT GENERATED
   - âŒ Segment 18: Verse backing track - NOT GENERATED
   - **Blocker**: Recursion error on both MPS and CPU (`maximum recursion depth exceeded`)
   - **Tried**: MPS (recursion error), CPU + float16 (too slow), CPU + float32 (still recursion error)
   - **Decision**: Mark as non-functional for MVP, focus on Bark comparison

**Outputs**:
- âœ… 2/4 WAV files generated (Bark vocals working)
- âœ… `results/local_models/bark_segment10_chorus.wav` (14.12s, 24kHz)
- âœ… `results/local_models/bark_segment18_verse.wav` (14.28s, 24kHz)
- âŒ Stable Audio blocked on technical incompatibility (recursion error)
- âœ… Complete documentation: `PHASE3_PROGRESS.md` + `PHASE3_FINAL_STATUS.md`

**MVP Impact**: Adjusted from 3-way comparison (Suno/Bark/Stable Audio) to 2-way (Suno/Bark)

---

### Phase 4: Audio Analysis (librosa) âœ… COMPLETE
**Goal**: Compare Suno baseline vs Bark vocals (adjusted scope)

**Comparison pairs**:
- Segment 10: `suno_segment10_chorus.wav` vs `bark_segment10_chorus.wav`
- Segment 18: `suno_segment18_verse.wav` vs `bark_segment18_verse.wav`

**Tasks**:
1. âœ… **Build comparison script**:
   - Load baseline + Bark WAVs (2 pairs)
   - Extract features: tempo, spectral centroid, MFCCs, chroma, ZCR, RMS energy
   - Calculate differences/similarities (absolute + percentage)
   - Cosine similarity for timbre (MFCC) and harmony (Chroma)
2. âœ… **Generate comparison report**:
   - Quantitative metrics (tempo match, spectral similarity)
   - Qualitative notes (vocal quality, coherence, energy)
   - Note: 2-way comparison (Stable Audio non-functional)

**Outputs**:
- âœ… `scripts/compare_audio.py` (librosa-based comparison tool)
- âœ… `results/analysis/comparison_results.json` (raw metrics)
- âœ… `results/analysis/comparison_results.md` (human-readable analysis)

**Key Findings**:
- **Strengths**: 94% timbre similarity, decent tempo tracking, 91% harmonic match in chorus
- **Weaknesses**: Duration limit (~14s), 4x noisier, poor verse harmony (45%), inconsistent loudness
- **Conclusion**: Local vocal generation viable but quality gap substantial vs Suno

---

### Phase 5: Presentation Prep
**Goal**: Package findings for AI Whisperers talk

**Tasks**:
1. **Organize audio files** for easy playback
2. **Document learnings**:
   - What worked well (which models/segments)
   - What didn't work (limitations discovered)
   - Journey insights (process over perfection)
3. **Prepare demo**:
   - Play Suno baseline
   - Play local model comparisons
   - Discuss findings

**Outputs**:
- Presentation-ready audio files
- Talking points/notes
- (Optional) Simple slides or visuals

---

## File Structure

```
research/code-first-protocol/
â”œâ”€â”€ CLAUDE.md                              # Agent instructions
â”œâ”€â”€ PLAN.md                                # This file
â”œâ”€â”€ README.md                              # Project overview
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ baseline/                          # Suno.ai originals (source of truth)
â”‚   â”‚   â”œâ”€â”€ Whispers_del_Futuro.wav        # Original Suno song
â”‚   â”‚   â”œâ”€â”€ Whispers_del_Futuro.json       # 42 segment analysis
â”‚   â”‚   â”œâ”€â”€ SONG.md                        # Full lyrics + metadata
â”‚   â”‚   â”œâ”€â”€ suno_segment7_instrumental.wav # (to be generated)
â”‚   â”‚   â”œâ”€â”€ suno_segment10_chorus.wav      # (to be generated)
â”‚   â”‚   â””â”€â”€ suno_segment18_verse.wav       # (to be generated)
â”‚   â””â”€â”€ segments/                          # Test segment definitions
â”‚       â””â”€â”€ suno_test_segments.md          # 3 segments for comparison
â”œâ”€â”€ scripts/                               # Generation + analysis tools
â”‚   â”œâ”€â”€ generate_musicgen.py               # (to be created)
â”‚   â”œâ”€â”€ generate_bark.py                   # (to be created)
â”‚   â”œâ”€â”€ generate_stable_audio.py           # (to be created)
â”‚   â””â”€â”€ compare_audio.py                   # (to be created)
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ local_models/                      # Local model outputs
â”‚   â”‚   â”œâ”€â”€ musicgen_segment7.wav
â”‚   â”‚   â”œâ”€â”€ musicgen_segment18.wav
â”‚   â”‚   â”œâ”€â”€ bark_segment10.wav
â”‚   â”‚   â”œâ”€â”€ bark_segment18.wav
â”‚   â”‚   â”œâ”€â”€ stable_audio_segment7.wav
â”‚   â”‚   â””â”€â”€ stable_audio_segment18.wav
â”‚   â””â”€â”€ analysis/                          # Comparison findings
â”‚       â””â”€â”€ comparison_results.md
â””â”€â”€ docs/
    â”œâ”€â”€ external/                          # External reference (points outward)
    â”‚   â”œâ”€â”€ AI_Music_Generation_Implementation_Guide.md # Production implementation patterns
    â”‚   â”œâ”€â”€ Open_Source_LLM_Guide.md       # Model catalog
    â”‚   â””â”€â”€ LLM_Documentation_Reference.md # Model docs + links
    â”œâ”€â”€ workflows/                         # How-to processes
    â”‚   â”œâ”€â”€ external-vs-internal-documentation.md
    â”‚   â””â”€â”€ project-reorganization-for-discovery.md
    â”œâ”€â”€ observations/                      # Learnings + insights
    â”‚   â””â”€â”€ 2025-11-08-practicing-discovery-protocol.md
    â””â”€â”€ archive/                           # Catalog of archived files (git is source)
        â””â”€â”€ ARCHIVED-2025-11-08-teach-discovery-research.md
```

---

## Success Criteria

**Minimum Viable** (Adjusted):
- âœ… 3 Suno baseline segments generated
- âš ï¸ At least 2 local models working â†’ **1 model working (Bark)**
  - âœ… Bark: Vocals (2 segments generated)
  - âŒ Stable Audio: Non-functional (recursion errors)
  - â¸ï¸ MusicGen: Deferred (Docker required for PyAV compatibility)
- âœ… Audio comparison with librosa (comprehensive metrics)
- âœ… Presentation-ready files + analysis

**Achieved Stretch Goals**:
- âœ… Detailed analysis writeup (comparison_results.md with quantitative + qualitative findings)

**Unachieved Stretch Goals**:
- âŒ Stable Audio Open working (technical blocker)
- âŒ Visual comparison charts (not needed - metrics sufficient)
- âŒ Live generation demo (Bark takes 30-60s per segment)

---

## Known Constraints

1. **Model limitations** (details in `docs/external/AI_Music_Generation_Implementation_Guide.md`):
   - MusicGen: No vocals (instrumental only), 30-second limit, CPU-bound despite GPU
   - Bark: Max ~13 seconds or 24 words (hard limit), requires chunking for longer audio
   - Stable Audio Open: 47 seconds max (not 11 - guide corrects this)
   - Memory: MusicGen needs 6-8GB (small) or 16GB (medium), Bark needs 2GB with optimizations

2. **Time constraint**: 4 days â†’ prioritize working demo over perfection

3. **Presentation focus**: Journey/learnings > perfect recreation

4. **Implementation gotchas** (see guide for details):
   - PyTorch version pinning critical (2.1.0 for MusicGen, avoid 2.5.0 for Bark)
   - Memory leaks require explicit cleanup between generations
   - FFmpeg integration needed for audio format conversion

---

## Project Status Summary

**Completed Phases**:
- âœ… Phase 1: Suno baseline generation (3 segments)
- âœ… Phase 2: Local model setup (Bark working, Stable Audio/MusicGen definitively blocked)
- âœ… Phase 3: Local model generation (2 Bark vocal segments)
- âœ… Phase 4: Audio analysis (librosa comparison complete)
- âœ… Phase 5: Presentation prep (COMPLETE - ready for Tuesday evening)

**Final MVP Status**:
- âœ… Working: Suno baseline (3 segments) + Bark vocals (2 segments) + librosa analysis
- âŒ Blocked: Stable Audio (recursion errors), MusicGen (PyAV/ffmpeg incompatibility in both venv and Docker)
- ğŸ“Š Result: 2-way comparison (Suno vs Bark) with quantitative metrics

**Deliverables**:
1. âœ… 3 Suno baseline segments (`data/baseline/*.wav`)
2. âœ… 2 Bark vocal segments (`results/local_models/bark_*.wav`)
3. âœ… Comprehensive analysis (`results/analysis/comparison_results.md` + `.json`)
4. âœ… Technical documentation (`PHASE3_FINAL_STATUS.md`, `PLAN.md`)

**Presentation Materials** (Tuesday evening):
- ğŸ“„ `PRESENTATION_SUMMARY.md` - Concise speaking notes (12 min talk)
- âœ… `PRESENTATION_CHECKLIST.md` - Pre-talk setup guide (15 min prep)
- ğŸ“Š `results/analysis/comparison_results.md` - Detailed metrics
- ğŸµ Audio files ready: 2 Suno baselines + 2 Bark outputs
- ğŸ“ `PHASE3_FINAL_STATUS.md` - Technical deep-dive (for Q&A)

---

**Created**: 2025-11-08 (Saturday 1pm)
**Last Updated**: 2025-11-09 (Sunday 8pm)
**Status**: âœ… ALL PHASES COMPLETE - Ready for Tuesday evening presentation

---

## Final Summary

**What We Achieved**:
- âœ… 2-way AI music generation comparison (Suno vs Bark)
- âœ… Quantitative analysis with librosa (tempo, timbre, harmony, noisiness)
- âœ… Honest documentation of technical blockers (Stable Audio, MusicGen)
- âœ… Complete presentation materials (summary, checklist, metrics)

**Key Findings**:
- Bark generates recognizable vocals but 4x noisier than Suno
- 94% timbre similarity shows promise, but duration limits (~14s) and quality gaps remain
- Open-source AI music generation is maturing but not production-ready
- Commercial models (Suno) maintain significant lead

**Lessons Learned**:
- CPU-only local generation is viable for experimentation
- Dependency management critical (PyTorch versions, ffmpeg APIs)
- MVP flexibility essential (adjusted from 3-way to 2-way comparison)
- Measurement validates intuition (librosa metrics quantify quality gap)

**Timeline**:
- Day 1 (Sat): Baseline generation, model setup planning
- Day 2 (Sun): Bark generation (5 attempts to fix bugs), Stable Audio debugging, analysis
- Day 3 (Sun eve): MusicGen Docker attempts, presentation prep
- Day 4 (Tue): Presentation at AI Whisperers Buenos Aires

**ğŸŒˆ Journey over perfection achieved â¤ï¸+ğŸŒ€=ğŸŒˆ**
